{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4778c52-0658-4bcd-a085-8b88aad2597c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8399e0-2893-4a6a-9e4e-972bff88111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")\n",
    "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b17cc-a60f-452d-a892-2a510ad6cdb7",
   "metadata": {},
   "source": [
    "Description\n",
    "---\n",
    "\n",
    "- Use the pretrained NVIDIA Segformer model to classify pixels\n",
    "- Select only class 2\n",
    "- Save image, masked pixels filled with 0 --> street_segm0.jpg\n",
    "- Create bounding box containing the class 2 pixels, save image --> street_segmbbox.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caaf69-1172-41b0-9c7b-582947f2612b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = '/work/ka1176/caroline/gitlab/AI4EO-MapYourCity/data/AI4EO-MapYourCity/v1/building-age-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d7680-07d3-4da0-b381-58c7de73e537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "data_path = os.path.join(data_root, split, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676f4c9-7152-4b4f-8f75-28675bcaf9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_root, split, f'{split}-set.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949a994-9e48-48e1-952c-e1c0c38bc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_filename = 'street.jpg'\n",
    "target_filename = 'street_segm0.jpg'\n",
    "target_bb_filename = 'street_segmbox.jpg'\n",
    "target_patch_filename = 'street_patch_tiny.jpg'\n",
    "mask_filename = 'is_house.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a05435-7f27-4dcb-b7fa-85c6e0d69e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d937f-e493-4dc5-aedb-8443b6f093a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "problem_pids = ['bdpfdxr3yo', 'g3gzdwy6t8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11712d-2deb-45de-bee8-680665ccbd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_frac = 0.85\n",
    "scale = (0.08, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e65056-f611-4605-bdb5-45a4fa03758a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pid in df['pid'].values[::-1]:\n",
    "    #if pid in problem_pids:\n",
    "    #    continue\n",
    "    \n",
    "    if not os.path.exists(os.path.join(data_path, pid, source_filename)):\n",
    "        print('missing source', pid)\n",
    "        continue\n",
    "    \n",
    "    if os.path.exists(os.path.join(data_path, pid, target_filename)) and \\\n",
    "       os.path.exists(os.path.join(data_path, pid, target_patch_filename)):\n",
    "        if not overwrite: continue    \n",
    "    \n",
    "    with open(os.path.join(data_path, pid, source_filename), 'rb') as ff:\n",
    "        image = Image.open(ff)\n",
    "        image.load()\n",
    "        image = image.convert(\"RGB\")\n",
    "        raw = plt.imread(os.path.join(data_path, pid, source_filename))\n",
    "        \n",
    "        # Segment\n",
    "        inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        # Get predicted map\n",
    "        predicted_segmentation_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "        predicted_segmentation_map = predicted_segmentation_map.cpu().numpy()\n",
    "        \n",
    "        # Mask: Keep only class 2 (which I assume is \"house\")\n",
    "        if not 2 in np.unique(predicted_segmentation_map):\n",
    "            print(f'Class not found in PID {pid}: Keep original image')\n",
    "            image.save(os.path.join(data_path, pid, target_filename))\n",
    "            image.save(os.path.join(data_path, pid, target_bb_filename))\n",
    "            image.save(os.path.join(data_path, pid, target_patch_filename))\n",
    "            #mask = np.ma.make_mask(predicted_segmentation_map==2)\n",
    "            #mask[:,:] = 1\n",
    "            #np.save(os.path.join(data_path, pid, mask_filename), mask)\n",
    "            \n",
    "            continue\n",
    "        mask = np.ma.make_mask(predicted_segmentation_map==2)\n",
    "        np.save(os.path.join(data_path, pid, mask_filename), mask)\n",
    "        masked_raw = np.where(np.dstack([mask, mask, mask]), raw, 0)\n",
    "        \n",
    "        # Sample random patch\n",
    "        img = plt.imread(os.path.join(data_path, pid, 'street.jpg'))\n",
    "        \n",
    "        keep_sampling = True\n",
    "        s=0\n",
    "        stacked = torch.dstack((torch.Tensor(img), torch.Tensor(mask).unsqueeze(-1)))\n",
    "        stacked = stacked.transpose(0, 2).transpose(1, 2)   \n",
    "        \n",
    "        while keep_sampling:\n",
    "            rrcrop = v2.RandomResizedCrop(384, scale=scale, interpolation=3)\n",
    "            timg = rrcrop(stacked).numpy().transpose(1,2,0)   \n",
    "            crmask = timg[:,:,-1]\n",
    "            frac = crmask.sum()/np.prod(crmask.shape)\n",
    "            s+=1\n",
    "            \n",
    "            if frac > min_frac or s > 25:\n",
    "                keep_sampling = False\n",
    "                \n",
    "        timg = timg[:,:,:3]\n",
    "        \n",
    "        patch = Image.fromarray(timg.astype(np.uint8))\n",
    "        patch.save(os.path.join(data_path, pid, target_patch_filename))\n",
    "        print(f'House fraction {frac:.2f} in {s} tries')\n",
    "        \n",
    "        # Bounding box encompassing the house in the segmentation map\n",
    "        segmentation = np.where(mask==True)\n",
    "        x_min = int(np.min(segmentation[1]))\n",
    "        x_max = int(np.max(segmentation[1]))\n",
    "        y_min = int(np.min(segmentation[0]))\n",
    "        y_max = int(np.max(segmentation[0]))\n",
    "        bb = raw[y_min:y_max, x_min:x_max]\n",
    "                \n",
    "        # Save as image\n",
    "        masked_image = Image.fromarray(masked_raw)\n",
    "        masked_image.save(os.path.join(data_path, pid, target_filename))\n",
    "        \n",
    "        bbox_image = Image.fromarray(bb)\n",
    "        bbox_image.save(os.path.join(data_path, pid, target_bb_filename))\n",
    "        print(f'Targets created for PID {pid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceeaf01-02ad-49fd-8efe-45a835698d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex=False, sharey=False, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "pid = 'mxgek8kuqt'\n",
    "ax[0].imshow(plt.imread(os.path.join(data_path, pid, source_filename)))\n",
    "ax[1].imshow(plt.imread(os.path.join(data_path, pid, target_filename)));\n",
    "ax[2].imshow(plt.imread(os.path.join(data_path, pid, target_bb_filename)));\n",
    "ax[3].imshow(plt.imread(os.path.join(data_path, pid, target_patch_filename)));\n",
    "ax[4].imshow(np.load(os.path.join(data_path, pid, mask_filename)));"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb2ada3-b518-4778-9024-90da6425e471",
   "metadata": {},
   "source": [
    "hgwbygcoqg Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efee3b-204b-4f59-96ad-663397a8b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MapYourCity (AI4EO)",
   "language": "python",
   "name": "map-city"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
